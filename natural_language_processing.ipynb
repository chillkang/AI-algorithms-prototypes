{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n\n", "    #Exercise 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import nltk\n", "nltk.download('book')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.book import *\n", "print(text1, text2, text3, text4, text5, text6, text7, text8, text9)\n\n", "    #enable us to see words in context\n", "    #shows every occurrence of a given word together with some context \n", "text1.concordance(\"monstrous\")\n\n", "    #words in similar range of contexts\n", "text1.similar(\"monstrous\")\n", "text2.similar(\"monstrous\")\n\n", "    #contexts shared by two or more words\n", "text2.common_contexts([\"monstrous\", \"very\"])\n\n", "    #finding definitions and usage of words in Wordnet\n", "from nltk.corpus import wordnet\n", "syn = wordnet.synsets('pain')\n", "print(syn[0].definition())\n", "print(syn[0].examples())\n\n", "    #synonyms\n", "synonyms = []\n", "for syn in wordnet.synsets('pain'):\n", "        for lemma in syn.lemmas():\n", "            synonyms.append(lemma.name())\n", "print(synonyms)\n\n", "    #antonyms\n", "antonyms = []\n", "for syn in wordnet.synsets('pain'):\n", "        for l in syn.lemmas():\n", "            if l.antonyms():\n", "                antonyms.append(l.antonyms()[0].name())\n", "print(antonyms)\n\n", "    #comparative wordlist\n", "    #NLTK includeing Swadesh wordlists (lists of about 200 common words in several languages) \n", "    #The languages are identified using an ISO 639 two-letter code.\n", "from nltk.corpus import swadesh\n", "print(swadesh.fileids())\n", "print(swadesh.words('en'))\n\n", "    #access cognate words from multiple languages using the entries() method, \n", "    #convert this into a simple dictionary \n", "fr2en = swadesh.entries(['fr', 'en'])\n", "print(fr2en)\n", "translate = dict(fr2en)\n", "print(translate['chien'])\n", "print(translate['jeter'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #build classifiers that will automatically tag new documents with appropriate category labels\n", "import random"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.corpus import movie_reviews\n", "documents = [(list(movie_reviews.words(fileid)), category)\n", "             for category in movie_reviews.categories()\n", "             for fileid in movie_reviews.fileids(category)]\n", "print(random.shuffle(documents))\n\n", "    #define a feature extractor for documents\n", "    #limit the number of features that the classifier needs to process to 2000 most frequent words\n", "    #define a feature extractor that simply checks whether each of these words is present in a given document\n", "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n", "word_features = list(all_words)[:2000] "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def document_features(document): \n", "    document_words = set(document) \n", "    features = {}\n", "    for word in word_features:\n", "        features['contains({})'.format(word)] = (word in document_words)\n", "    return features\n", "print(document_features(movie_reviews.words('pos/cv957_8737.txt'))) \n\n", "    #use feature extractor to train a classifier to label new movie reviews. \n", "featuresets = [(document_features(d), c) for (d,c) in documents]\n", "train_set, test_set = featuresets[100:], featuresets[:100]\n", "classifier = nltk.NaiveBayesClassifier.train(train_set)\n\n", "    #compute its accuracy on the test set\n", "    #use show_most_informative_features() to find out which features the classifier found to be most informative.\n", "print(nltk.classify.accuracy(classifier, test_set))\n", "classifier.show_most_informative_features(5) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #Exervise 2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nltk.download('book')\n", "from nltk.book import *"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text1.concordance(\"however\")\n", "text2.concordance(\"however\")\n", "text3.concordance(\"however\")\n", "text4.concordance(\"however\")\n", "text5.concordance(\"however\")\n", "text6.concordance(\"however\")\n", "text7.concordance(\"however\")\n", "text8.concordance(\"however\")\n", "text9.concordance(\"however\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.corpus import wordnet\n", "syn = wordnet.synsets('however')\n", "print(syn[4].definition())\n", "print(syn[4].examples())\n\n", "    # =============================================================================\n", "    # despite anything to the contrary (usually following a concession)\n", "    # [\"although I'm a little afraid, however I'd like to try it\", \n", "    # 'while we disliked each other, nevertheless we agreed', 'he was a stern yet fair master', \n", "    # 'granted that it is dangerous, all the same I still want to go']\n", "    # \n", "    # =============================================================================\n\n", "    # =============================================================================\n", "    # by contrast; on the other hand\n", "    # ['the first part was easy; the second, however, took hours']\n", "    # =============================================================================\n", "    \n", "    # =============================================================================\n", "    # in whatever way or manner\n", "    # ['Victory, however it was brought about, was sweet', 'however he did it, it was very clever']\n", "    # =============================================================================\n\n", "    #Exercise 3\n", "nltk.download('book')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.book import *\n", "    # =============================================================================\n", "    # print(text1, text2, text3, text4, text5, text6, text7, text8, text9)\n", "    # <Text: Moby Dick by Herman Melville 1851> <Text: Sense and Sensibility by Jane Austen 1811> \n", "    # <Text: The Book of Genesis> <Text: Inaugural Address Corpus> <Text: Chat Corpus> \n", "    # <Text: Monty Python and the Holy Grail> <Text: Wall Street Journal> <Text: Personals Corpus> \n", "    # <Text: The Man Who Was Thursday by G . K . Chesterton 1908>\n", "    # \n", "    # ============================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text2.similar(\"love\") \n", "    # =============================================================================\n", "    # affection sister heart mother time see town life it dear elinor \n", "    # marianne me word family her him do regard head\n", "    # ============================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text3.similar(\"love\")\n", "    # =============================================================================\n", "    # went drank earth darkness morning se them give nig hath man had thus\n", "    # not took keep die call sle woman\n", "    # ============================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text2.similar(\"beginning\") \n", "    # =============================================================================\n", "    # time moment family house it not goodness heart what only first way\n", "    # whole hope danger enough situation going determined knowledge\n", "    # ============================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text3.similar(\"beginning\") \n", "    # =============================================================================\n", "    # lord garden way god earth face spirit waters good day firmament midst\n", "    # place land gathering herb fruit tree days stars\n", "    # =============================================================================\n\n", "    #contexts shared by two or more words\n", "text2.common_contexts([\"love\", \"affection\"])\n", "    #_for her_and his_for s_it and_to s_and his_was her_for"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text3.common_contexts([\"love\", \"earth\"])\n", "text3.common_contexts([\"love\", \"morning\"])\n", "    #the_he"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text2.common_contexts([\"beginning\", \"time\"])\n", "    #the_of a_as the_to"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text3.common_contexts([\"beginning\", \"lord\"])\n", "text3.common_contexts([\"beginning\", \"garden\"])\n", "    #the_of the_god\n", "    \n", "    #Exercise 4"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.corpus import swadesh\n", "en2it = swadesh.entries(['en', 'it'])\n", "translate = dict(en2it)\n", "print(translate['mountain']) #montagna\n", "print(translate['wind']) #vento\n", "print(translate['eat']) #mangiare\n", "print(translate['forest']) #foresta"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["en2es = swadesh.entries(['en', 'es'])\n", "translate = dict(en2es)\n", "print(translate['mountain']) #monta\u00f1a\n", "print(translate['wind']) #viento\n", "print(translate['eat']) #comer\n", "print(translate['forest']) #bosque"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["en2fr = swadesh.entries(['en', 'fr'])\n", "translate = dict(en2fr)\n", "print(translate['mountain']) #montagne\n", "print(translate['wind']) #vent\n", "print(translate['eat']) #manger\n", "print(translate['forest']) #for\u00eat"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["en2sl = swadesh.entries(['en', 'sl'])\n", "translate = dict(en2sl)\n", "print(translate['mountain']) #gora\n", "print(translate['wind']) #veter\n", "print(translate['eat']) #jesti\n", "print(translate['forest']) #gozd"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}